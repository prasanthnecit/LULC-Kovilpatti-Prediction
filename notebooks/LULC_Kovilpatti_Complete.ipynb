{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# \ud83c\udf0d Complete LULC Prediction System for Kovilpatti\n",
        "\n",
        "## Causal Spatiotemporal Transformer for Land Use/Land Cover Prediction\n",
        "\n",
        "This notebook provides a complete interactive workflow for LULC prediction."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Installation and Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "sys.path.insert(0, str(Path.cwd().parent))\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "from src.data_generator import KovilpattiLULCGenerator\n",
        "from src.dataset import TemporalLULCDataset\n",
        "from src.model import CausalSpatiotemporalTransformer, PhysicsInformedLoss\n",
        "from src.train import train_epoch, validate\n",
        "from src.utils import set_seed, predict_future_multistep, create_confusion_matrix\n",
        "\n",
        "print('\u2705 Imports successful!')\n",
        "print(f'PyTorch version: {torch.__version__}')\n",
        "print(f'CUDA available: {torch.cuda.is_available()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "set_seed(42)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Using device: {device}')\n",
        "\n",
        "config = {\n",
        "    'data': {'img_size': 256, 'num_classes': 7, 'train_samples': 200, 'val_samples': 40, 'test_samples': 40},\n",
        "    'model': {'d_model': 256, 'n_heads': 8, 'n_layers': 4, 'dropout': 0.1},\n",
        "    'training': {'batch_size': 8, 'num_epochs': 50, 'learning_rate': 0.0001, 'lambda_physics': 0.1, 'lambda_continuity': 0.05}\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Data Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "generator = KovilpattiLULCGenerator(img_size=256, num_classes=7)\n",
        "sequence = generator.generate_temporal_sequence(num_timesteps=5)\n",
        "\n",
        "fig, axes = plt.subplots(1, 5, figsize=(20, 4))\n",
        "for idx, lulc_map in enumerate(sequence):\n",
        "    rgb = generator.lulc_to_rgb(lulc_map)\n",
        "    axes[idx].imshow(rgb)\n",
        "    axes[idx].set_title(f'Year {2018+idx}')\n",
        "    axes[idx].axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Generate Full Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_dir = Path('../data/Kovilpatti_LULC')\n",
        "for split, n in [('train', 200), ('val', 40), ('test', 40)]:\n",
        "    split_dir = data_dir / split\n",
        "    split_dir.mkdir(parents=True, exist_ok=True)\n",
        "    for i in tqdm(range(n), desc=split):\n",
        "        seq = generator.generate_temporal_sequence(5)\n",
        "        np.save(split_dir / f'sequence_{i:04d}.npy', np.stack(seq))\n",
        "print('\u2705 Dataset generated!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Load Datasets and Create Dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_dataset = TemporalLULCDataset(str(data_dir), 'train', 256, 7)\n",
        "val_dataset = TemporalLULCDataset(str(data_dir), 'val', 256, 7)\n",
        "test_dataset = TemporalLULCDataset(str(data_dir), 'test', 256, 7)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, num_workers=2)\n",
        "\n",
        "print(f'Train: {len(train_dataset)}, Val: {len(val_dataset)}, Test: {len(test_dataset)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Initialize Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = CausalSpatiotemporalTransformer(num_classes=7, d_model=256, n_heads=8, n_layers=4).to(device)\n",
        "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f'Model parameters: {num_params:,}')\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "physics_loss_fn = PhysicsInformedLoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0001, weight_decay=0.0001)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "history = {'train_loss': [], 'val_loss': [], 'train_accuracy': [], 'val_accuracy': []}\n",
        "training_config = {'lambda_physics': 0.1, 'lambda_continuity': 0.05}\n",
        "\n",
        "for epoch in range(10):  # Reduced for demo\n",
        "    train_metrics = train_epoch(model, train_loader, criterion, physics_loss_fn, optimizer, device, training_config)\n",
        "    val_metrics = validate(model, val_loader, criterion, physics_loss_fn, device, training_config)\n",
        "    \n",
        "    history['train_loss'].append(train_metrics['loss'])\n",
        "    history['val_loss'].append(val_metrics['loss'])\n",
        "    history['train_accuracy'].append(train_metrics['accuracy'])\n",
        "    history['val_accuracy'].append(val_metrics['accuracy'])\n",
        "    \n",
        "    print(f\"Epoch {epoch+1}: Train Loss={train_metrics['loss']:.4f}, Val Loss={val_metrics['loss']:.4f}\")\n",
        "\n",
        "print('\u2705 Training complete!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history['train_loss'], label='Train')\n",
        "plt.plot(history['val_loss'], label='Val')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.title('Loss Curves')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history['train_accuracy'], label='Train')\n",
        "plt.plot(history['val_accuracy'], label='Val')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.title('Accuracy Curves')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Test Evaluation and Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_metrics = validate(model, test_loader, criterion, physics_loss_fn, device, training_config)\n",
        "print(f\"Test Accuracy: {test_metrics['accuracy']:.4f}\")\n",
        "print(f\"Test F1: {test_metrics['f1']:.4f}\")\n",
        "print(f\"Test Kappa: {test_metrics['kappa']:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Multi-Step Forecasting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "inputs, target, _ = next(iter(test_loader))\n",
        "sample_input = inputs[0]  # First sample\n",
        "\n",
        "future_preds = predict_future_multistep(model, sample_input, num_steps=3, device=device)\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "for idx, pred in enumerate(future_preds):\n",
        "    pred_class = torch.argmax(pred, dim=0).numpy()\n",
        "    rgb = generator.lulc_to_rgb(pred_class)\n",
        "    axes[idx].imshow(rgb)\n",
        "    axes[idx].set_title(f'Year {2023+idx}')\n",
        "    axes[idx].axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Summary\n\nThis notebook demonstrated:\n- Data generation for Kovilpatti LULC\n- Model training with physics constraints\n- Prediction and evaluation\n- Multi-step forecasting"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}